{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ls /haarcascades/`\n",
    "***\n",
    "**`haarcascade_eye.xml`**\n",
    "\n",
    "`haarcascade_eye_tree_eyeglasses.xml\n",
    "haarcascade_frontalcatface.xml\n",
    "haarcascade_frontalcatface_extended.xml\n",
    "haarcascade_frontalface_alt.xml`\n",
    "\n",
    "**`haarcascade_frontalface_alt2.xml`**\n",
    "\n",
    "`haarcascade_frontalface_alt_tree.xml\n",
    "haarcascade_frontalface_default.xml\n",
    "haarcascade_fullbody.xml\n",
    "haarcascade_lefteye_2splits.xml\n",
    "haarcascade_licence_plate_rus_16stages.xml\n",
    "haarcascade_lowerbody.xml\n",
    "haarcascade_profileface.xml\n",
    "haarcascade_righteye_2splits.xml\n",
    "haarcascade_russian_plate_number.xml\n",
    "haarcascade_smile.xml\n",
    "haarcascade_upperbody.xml\n",
    "haarcascade_mcs_eyepair_big.xml\n",
    "haarcascade_mcs_eyepair_small.xml\n",
    "haarcascade_mcs_leftear.xml\n",
    "haarcascade_mcs_lefteye.xml\n",
    "haarcascade_mcs_lefteye_alt.xml`\n",
    "\n",
    "**`haarcascade_mcs_mouth.xml\n",
    "haarcascade_mcs_nose.xml`**\n",
    "\n",
    "`haarcascade_mcs_rightear.xml\n",
    "haarcascade_mcs_righteye.xml\n",
    "haarcascade_mcs_righteye_alt.xml\n",
    "haarcascade_mcs_upperbody.xml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import imutils\n",
    "from timeit import default_timer as timer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`FoundSubFeature` class holds advanced properties of subface-features** instead of default [x,y,w,h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FoundSubFeature:\n",
    "    def __init__(self,parent,subf_x,subf_y,subf_w,subf_h,face_x,face_y,face_w,face_h):\n",
    "        self.parent = parent\n",
    "        self.midpoint = [subf_x+subf_w/2,subf_y+subf_h/2]\n",
    "\n",
    "        self.face_midpoint = [face_x+face_w/2,face_y+face_h/2]\n",
    "        self.relative_midpoint = [self.midpoint[0]-face_w/2,self.midpoint[1]-face_h/2]\n",
    "        self.relative_midpoint_percentage = [self.relative_midpoint[0]/face_w*100,self.relative_midpoint[1]/face_h*100]\n",
    "\n",
    "        self.bounding_box = [subf_w,subf_h]\n",
    "        self.size = subf_w*subf_h\n",
    "        self.face_box = [face_w,face_h]\n",
    "        face_size = face_w*face_h\n",
    "        self.relative_size = self.size/face_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** `detector` represents the Viola-Jones detector **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detector(img,face_cascade,subfeature_cascades):\n",
    "\n",
    "    result = []\n",
    "    face_index = 0\n",
    "\n",
    "    # img = imutils.resize(img, width = 300)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    found_faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "    for (face_x,face_y,face_w,face_h) in found_faces:\n",
    "        \n",
    "        face_index += 1\n",
    "\n",
    "        # face rectangles\n",
    "        cv2.rectangle(img,(face_x,face_y),(face_x+face_w,face_y+face_h),(241,240,236),2)\n",
    "\n",
    "        # roi based on found_faces\n",
    "        roi_gray = gray[face_y:face_y+face_h, face_x:face_x+face_w]\n",
    "        roi_color = img[face_y:face_y+face_h, face_x:face_x+face_w]\n",
    "\n",
    "        # applying subfeature_cascades\n",
    "        found_subfeatures = []\n",
    "        \n",
    "        for cascade in subfeature_cascades:\n",
    "            found_subfeatures.append([])\n",
    "            objects = cascade.detectMultiScale(roi_gray,scaleFactor=1.05)\n",
    "            if len(objects) != 0:\n",
    "                for element in objects.tolist():\n",
    "                    found_subfeatures[-1].append(FoundSubFeature(face_index,element[0],element[1],element[2],element[3],face_x,face_y,face_w,face_h))\n",
    "        result.append(found_subfeatures)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** usage of Viola-Jones detector **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('./databases/IMM-Frontal Face DB SMALL/01_01.jpg')\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "# cascades = []\n",
    "# cascades.append(cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml'))\n",
    "# cascades.append(cv2.CascadeClassifier('haarcascades/haarcascade_mcs_nose.xml'))\n",
    "# cascades.append(cv2.CascadeClassifier('haarcascades/haarcascade_mcs_mouth.xml'))\n",
    "\n",
    "# result = detector(img,face_cascade,cascades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** we need to declare a new drawing function based on `FoundSubFeature` class **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawRectangleForSubFeature(img,FoundSubFeature,color):   \n",
    "    vertex_1 = tuple([int(x) for x in [sum(element) for element in zip(FoundSubFeature.face_midpoint,FoundSubFeature.relative_midpoint,[x / -2 for x in FoundSubFeature.bounding_box])]])\n",
    "    vertex_2 = tuple([int(x) for x in [sum(element) for element in zip(FoundSubFeature.face_midpoint,FoundSubFeature.relative_midpoint,[x / 2 for x in FoundSubFeature.bounding_box])]])\n",
    "    cv2.rectangle(img,vertex_1,vertex_2,color,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clouds = [241, 240, 236]\n",
    "# alizarin = [60, 76, 231]\n",
    "# peterriver = [219, 152, 52]\n",
    "# nephritis = [96, 174, 39]\n",
    "# colors = [clouds,alizarin,peterriver,nephritis]\n",
    "\n",
    "# for face in result:\n",
    "#     i = -1                                              # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#     for subfeature in face:\n",
    "#         i += 1                                          # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#         for element in subfeature:\n",
    "#             drawRectangleForSubFeature(img,element,colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawImageDetection(image,result,features):\n",
    "    clouds = [241, 240, 236]\n",
    "    alizarin = [60, 76, 231]\n",
    "    peterriver = [219, 152, 52]\n",
    "    nephritis = [96, 174, 39]\n",
    "    colors = [clouds,alizarin,peterriver,nephritis]\n",
    "    \n",
    "    for face in result:\n",
    "        i = -1\n",
    "        for subfeature in face:\n",
    "            i += 1 # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            for element in subfeature:\n",
    "                drawRectangleForSubFeature(image,element,colors[i])\n",
    "    \n",
    "    for feature in features:\n",
    "        (x,y) = (550,300+features.index(feature)*50)\n",
    "        cv2.putText(image,feature,(x,y),cv2.FONT_HERSHEY_SIMPLEX, 2, colors[features.index(feature)])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawRectangleForSubFeature(img,result[0][2][4],[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** inline image display within a `Jupyter notebook` is a bit complicated... ** we need to declare a function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def showImage(image):\n",
    "    b,g,r = cv2.split(image)\n",
    "    img_rgb = cv2.merge([r,g,b])\n",
    "    \n",
    "    figure = plt.figure(figsize = (100,10))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# showImage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate Viola Jones Detector for each images in subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DetectedImage:\n",
    "    def __init__(self,image_name,image,result):\n",
    "        self.image_name = image_name\n",
    "        self.image = image\n",
    "        self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "directory = './databases/IMM-Frontal-Face-DB-SMALL'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "cascades = []\n",
    "cascades.append(cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml'))\n",
    "cascades.append(cv2.CascadeClassifier('haarcascades/haarcascade_mcs_nose.xml'))\n",
    "cascades.append(cv2.CascadeClassifier('haarcascades/haarcascade_mcs_mouth.xml'))\n",
    "\n",
    "features = ['eye','nose','mouth'] # used for printing on image\n",
    "\n",
    "detected_images = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        filepath = os.path.join(directory,filename)\n",
    "        \n",
    "        image = cv2.imread(filepath)\n",
    "        result = detector(image,face_cascade=face_cascade,subfeature_cascades=cascades)\n",
    "        \n",
    "        detected_images.append(DetectedImage(filename,image,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageindex = 10\n",
    "showImage(drawImageDetection(detected_images[imageindex].image,detected_images[imageindex].result,features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
